{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "G_EXTRACTING_RELEVANT_TWEETS.ipynb\n",
    "\n",
    "This notebook pulls out the relevant tweets out of the previously filtered tweets which match the following conditions:\n",
    "    1. Is from a user that has previously been located to IA, SC or MA\n",
    "    2. The tweet was posted during the 3-week period leading up to the respective dem primary\n",
    "    \n",
    "NL, 22/01/2020\n",
    "NL, 23/01/2020 -- first alpha for testing through sbatch\n",
    "    \n",
    "SEQUENCE:\n",
    "    1. data i/o\n",
    "    2. define date ranges\n",
    "    3. go through pertinent jsons and write the pertinent tweets to a (three) new json stream(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "import datetime\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/scratch/nl1676/olympus_local/sentiment_paper_relevant_tweets/\"\n",
    "TWEETS = glob.glob(DATA_PATH+\"*.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IO --> these are the users that had already been located\n",
    "ia_df = pd.read_csv(DATA_PATH + \"previously_located_users/iowa.csv\", dtype = {\"user_id\" : \"str\"})\n",
    "ma_df = pd.read_csv(DATA_PATH + \"previously_located_users/massachussets.csv\", dtype = {\"user_id\" : \"str\"})\n",
    "sc_df = pd.read_csv(DATA_PATH + \"previously_located_users/south_carolina.csv\", dtype = {\"user_id\" : \"str\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the unique user ids for each state into their own objects\n",
    "user_ids = [list(ia_df['user_id']), list(sc_df['user_id']), list(ma_df['user_id'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time frame of interest is 3 weeks leading up to each of 3 primaries: **New Hampshire [February 9, 2016], South Carolina [February 27, 2016], Massachusetts [March 1, 2016]**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_delta = datetime.timedelta(days = 1)\n",
    "\n",
    "# relevant date range: \n",
    "# create an array of all pertinent days\n",
    "start_ia = datetime.datetime.strptime(\"2016-01-19\", \"%Y-%m-%d\")\n",
    "end_ia = datetime.datetime.strptime(\"2016-02-09\", \"%Y-%m-%d\")\n",
    "start_sc = datetime.datetime.strptime(\"2016-02-06\", \"%Y-%m-%d\")\n",
    "end_sc = datetime.datetime.strptime(\"2016-02-27\", \"%Y-%m-%d\")\n",
    "start_ma = datetime.datetime.strptime(\"2016-02-09\", \"%Y-%m-%d\")\n",
    "end_ma = datetime.datetime.strptime(\"2016-03-01\", \"%Y-%m-%d\")\n",
    "date_range_ia = [start_ia + datetime.timedelta(days=x) for x in range(0, (end_ia-start_ia).days)]\n",
    "date_range_sc = [start_sc + datetime.timedelta(days=x) for x in range(0, (end_sc-start_sc).days)]\n",
    "date_range_ma = [start_ma + datetime.timedelta(days=x) for x in range(0, (end_ma-start_ma).days)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dates strings turns the dates into the right format for extracting the right collection files.\n",
    "\n",
    "all_state_dates = [date_range_ia, date_range_sc, date_range_ma]\n",
    "all_state_date_strings = [[],[],[]]\n",
    "\n",
    "for i,element in enumerate(all_state_dates):\n",
    "    for date in element:\n",
    "        pos1 = date.strftime(\"%m_%d_%Y\")\n",
    "        all_state_date_strings[i].append(pos1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing out pertinent files for each state\n",
    "pertinent_files = [[],[],[]]\n",
    "\n",
    "for i,element in enumerate(all_state_date_strings):\n",
    "    pertinent_files[i] = [x for x in TWEETS if sum([int(z in x) for z in all_state_date_strings[i]]) > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOW to iterate through all the relevant tweet files, and to write out those that I am interested in, \n",
    "to a new json file for each state! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(path, output_path, user_ids_list):\n",
    "    with open(path) as infile: \n",
    "        print(path)\n",
    "        for i,line in enumerate(infile):\n",
    "            try:\n",
    "                tweet = json.loads(line)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f'Error in {infile} line {i}: {e}')\n",
    "            user_id = tweet['user']['id_str']\n",
    "            if user_id in user_ids_list:\n",
    "                with open(output_path, 'a+') as outfile:\n",
    "                    newline = json.dumps(tweet)\n",
    "                    outfile.write(newline + '\\n')\n",
    "                    \n",
    "    print('Wrote tweets to json. Next file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-61-100af92ecbb7>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-61-100af92ecbb7>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "# LOOP through the states, then the files\n",
    "output_filepaths = [DATA_PATH+'located_users_tweets/iowa_tweets.json',\n",
    "                    DATA_PATH+'located_users_tweets/southcarolina_tweets.json',\n",
    "                    DATA_PATH+'located_users_tweets/massachussets_tweets.json']\n",
    "\n",
    "for i,element in enumerate(pertinent_files):\n",
    "    for j,file in enumerate(element):\n",
    "        process_file(path=file, output_path=output_filepaths[i], user_ids_list=user_ids[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
